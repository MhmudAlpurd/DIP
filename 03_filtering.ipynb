{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03 - Image filtering using the convolution operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous notebooks, image enhancement was achieved by taking as input only some given pixel evaluated at a coordinate $f(x,y)$. *Image filtering* considers a neighbourhood around the pixel to be processed, i.e. a region of pixels centred at coordinate $(x,y)$. Therefore, it produces a combination of neighbour pixels. When this combination is linear, we can write this transformation by means of a **convolution** operator.\n",
    "\n",
    "The convolution operator is formally written with the star operator `*`, allowing to differentiate it from a simple pixel-wise product. In terms of the whole image, it is given by:\n",
    "\n",
    "$$ g = w * f$$\n",
    "\n",
    "The equation above means the filtered (processed) image $g$ is obtained by a convolution of a processing element *w* (that defines the transformation) with the input image $f$. Note that now *w* will guide the way the transformation occurs. This processing element is called **filter** and it is organized as an array of weights.\n",
    "\n",
    "The convolution evaluated at some given coordinate $(x,y)$ filters a pixel of image $f$, producing a new pixel value, $g(x,y)$:\n",
    "\n",
    "$$ g(x,y) = \\sum_{s=-a}^{a} \\sum_{t=-b}^{b} w(s,t) \\cdot f(x-s, y-t)$$\n",
    "\n",
    "Note that for every value of $s$ and $t$ that indexes the filter $w(s,t)$, the convolution basically multiplies every value in $w$ with different positions around $f(x,y)$, using shifts defined by $s$ and $t$. \n",
    "\n",
    "Usually the filter is much smaller than $f$. Let us say $w$ has size `m x n` and $f$ is `M x N`. Another important remark is that this equation assumes the filter is centred at the origin $(0,0)$, thus the negative values of $s$ and $t$. \n",
    "\n",
    "Then, in order to process all values we want to make sure that: $m = 2a+1$ and $n = 2b+1$.\n",
    "\n",
    "Therefore, $a = \\frac{m-1}{2}$, $b = \\frac{n-1}{2}$, allowing to index from $-a$ to $a$ (centred at 0) and from $-b$ to $b$ (also centred at 0).\n",
    "\n",
    "Let us make an example with small matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(666) # defining a seed\n",
    "# random image with 5x5 size\n",
    "f = np.random.randint(0,7, [5,5])\n",
    "print(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us design some arbitrary filter *w* with size 3x3\n",
    "w = np.matrix([[1, 2, 0], [1, 4, 0], [0, 0, 0]])/8.0\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We wish to compute the convolution of $w$ with $f$, producing a new matrix/image $g$. In order to do so, we shall first understand how to compute the value of $g$ at a given pixel, for example $g(1,2)$.\n",
    "\n",
    "The input central value is $f(1,2) = 6$.\n",
    "\n",
    "The designed filter has size $3\\times 3$ and therefore, $m=n=3$. \n",
    "\n",
    "Let us compute the values of $a$ and $b$ which are the indices for the convolution double sum. In the general form that would be:\n",
    "$$ n = 2a + 1$$\n",
    "$$ 2a= n - 1$$\n",
    "$$ a = \\frac{n-1}{2} $$\n",
    "\n",
    "Plugging in the value of $n$\n",
    "$$ 3 = 2a + 1$$\n",
    "$$ 2a= 3 - 1$$\n",
    "$$ a = \\frac{2}{2} = 1 $$\n",
    "\n",
    "Therefore:\n",
    "\n",
    "$$ g(1,2) = \\sum_{s=-1}^{1} \\sum_{t=-1}^{1} w(s,t) \\cdot f(1-s, 2-t)$$\n",
    "\n",
    "Remember the equation considers that $w$ is centred at $(0,0)$, therefore the **indices** of filter $w$, are defined mathematically as follows:\n",
    "\n",
    "$$ \\begin{bmatrix}\n",
    " (-1,-1) & (0,-1) & (1,-1) \\\\ \n",
    " (-1, 0) & (0, 0) & (1, 0) \\\\ \n",
    " (-1, 1) & (0, 1) & (1, 1) \n",
    "\\end{bmatrix}$$\n",
    "\n",
    "Note that, in the code we dont have negative indices for arrays, so we are going to make some trick in that sense. But first, let us compute the convolution manually.\n",
    "\n",
    "In practice what the equation performs is to take every value in $w$, multiply it by the neighbours of $f(1,2)$, and sum all resulting values.\n",
    "\n",
    "So, we want to evaluate all terms $w(s,t) \\cdot f(1-s, 2-t)$: \n",
    "\n",
    "The first term of the double sum is for $t = -1$ and $s = -1$ (those are in parenthesis below):\n",
    "$$ w(-1,-1) \\cdot f(1- (-1) ,2- (-1)) = 0.125 \\cdot f(2,3)$$\n",
    "\n",
    "The second term, $t=-1, s=0$:\n",
    "$$ w(-1, 0) \\cdot f(1-(-1),2-(0)) = 0.125 \\cdot f(2,2)$$\n",
    "\n",
    "The third term, $t=-1, s=1$:\n",
    "$$ w(-1, 1) \\cdot f(1-(-1),2-(1)) = 0.0 \\cdot f(2,1)$$\n",
    "\n",
    "The forth term, $t=0, s=-1$:\n",
    "$$ w(0,-1) \\cdot f(1-(0),2-(-1)) = 0.25 \\cdot f(1,3)$$\n",
    "\n",
    "And so on. Note the three first values of the filter are related to the **first column** of the filter : `[0.125, 0.125 , 0.0  ]`. Those are multiplying the values at the **second row** of the image, but in inverted order, at coordinates:(2,3), (2,2) and (2,1) relative to the values: `[4, 3, 6]` (look for this sequence in the second row of the image, but in inverted order, that is due to the subtraction 1-s and 2-t on the definition of convolution)\n",
    "\n",
    "Therefore, the convolution performs a point-wise multiplication between the image pixels, centred at $(x,y)$, and the values of the *flipped filter*. This flipping may not make much sense in terms of image processing (whose information is spatial), but it does in terms of signal processing (time information), from which the definition of convolution comes from.\n",
    "\n",
    "Therefore, let us make the implementation easier by flipping the filter first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wf = np.flip( np.flip(w,0) , 1)\n",
    "print(wf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can just run a point-wise multiplication centred at (x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knowing we want to compute g(1,2), let us extract just the part of the matrix we need\n",
    "x = 1\n",
    "y = 2\n",
    "# using the a and b calculated before, we want the region x-1 to x+1, y-1 to y+1.\n",
    "# but, in Python the interval -A:B creates a sequence [A, A+1, A+2, ..., B-2, B-1], therefore we use 2 at the end\n",
    "# let us print the neighbourhood of (x=1,y=2)\n",
    "print(f[ x-1:x+2 , y-1:y+2 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, perform a point-wise multiplication between the region and the flipped filter\n",
    "conv1 = np.multiply(f[ x-1:x+2 , y-1:y+2 ], wf)\n",
    "conv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# then we sum every resulting value\n",
    "g_1_2 = np.sum(conv1)\n",
    "g_1_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this sum may be then converted to an integer value, by rounding the number (floor)\n",
    "g_1_2 = int(np.sum(conv1))\n",
    "g_1_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us implement our own function that performs convolution at some pixel x,y\n",
    "# assuming the filter has odd size (for n or m) to facilitate implementation\n",
    "def conv_point(f, w, x, y, debug=False):\n",
    "    n,m = w.shape\n",
    "    a = int((n-1)/2)\n",
    "    b = int((m-1)/2)\n",
    "    # gets submatrix of pixel neighbourhood\n",
    "    sub_f = f[ x-a : x+a+1 , y-b:y+b+1 ]\n",
    "\n",
    "    # flips the filter\n",
    "    w_flip = np.flip( np.flip(w, 0) , 1)\n",
    "    \n",
    "    # conditional for debugging the function by showing the arrays\n",
    "    if (debug==True):\n",
    "        print(\"sub-image f:\\n\" + str(sub_f))\n",
    "        print(\"\\nflipped filter w:\\n\" + str(w_flip))\n",
    "    \n",
    "    # performs convolution (without converting to int)\n",
    "    value = np.sum( np.multiply(sub_f, w_flip))\n",
    "    return value\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us test it for some coordinate\n",
    "conv_point(f, w, 3, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like it works! Now we may evaluate the convolution with $w$ on ALL pixels of $f$ and produce the filtered image $g$. To do that, let us implement a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performs convolution on all pixels of image f with filter w\n",
    "def image_convolution(f, w, debug=False):\n",
    "    N,M = f.shape\n",
    "    \n",
    "    # creates a new empty image to store processed values\n",
    "    g = np.empty(f.shape, dtype=np.uint8)\n",
    "    \n",
    "    # loops through each pixel:\n",
    "    for x in range(N):\n",
    "        for y in range(M):\n",
    "            # perform convolution converting to uint8\n",
    "            g[x,y] = conv_point(f, w, x, y, debug).astype(np.uint8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the function...\n",
    "g = image_convolution(f, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What should be the problem? It looked everything was ok. Let us use the debug argument as true to print out the matrices and filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = image_convolution(f, w, debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the function could not create a subimage $f$ for $f(0,0)$, because it tried to access **negative** index values. For exampel, for the filter we designed, $a = 1$ and $b = 1$, then the submatrix is given by:\n",
    "    \n",
    "`sub_f = f[ x-(a) : x+(a+1) , y-(b) : y+(b+1) ] \n",
    "       = f[ 0-(1) : 0+(1+1) , 0-(1) : 0-(1+1) ]\n",
    "       = f[   -1  :      2  ,   -1  :      2  ]`\n",
    "\n",
    "The interval contain regions of $f$ with index -1 at both row and collumn, which is out of the array bounds. Therefore, pixels at the border of the image cannot be computed in practice. Let us avoid them by processing only the pixels:\n",
    "\n",
    "x from `0+a` to `N-a`\n",
    "\n",
    "y from `0+b` to `M-b`\n",
    "\n",
    "Ignoring border pixels for now. Since we are modifying the functions we can also compute the *flipped filter* only once and perform the convolution so we have a self-contained image convolution function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_convolution(f, w, debug=False):\n",
    "    N,M = f.shape\n",
    "    n,m = w.shape\n",
    "    \n",
    "    a = int((n-1)/2)\n",
    "    b = int((m-1)/2)\n",
    "\n",
    "    # flipped filter\n",
    "    w_flip = np.flip( np.flip(w, 0) , 1)\n",
    "    # new image to store filtered pixels\n",
    "    g = np.zeros(f.shape, dtype=np.uint8)\n",
    "\n",
    "    # for every pixel\n",
    "    for x in range(a,N-a):\n",
    "        for y in range(b,M-b):\n",
    "            # gets subimage\n",
    "            sub_f = f[ x-a : x+a+1 , y-b:y+b+1 ]\n",
    "            if (debug==True):\n",
    "                print(str(x)+\",\"+str(y)+\" - subimage:\\n\"+str(sub_f))\n",
    "            # computes g at (x,y)\n",
    "            g[x,y] = np.sum( np.multiply(sub_f, w_flip)).astype(np.uint8)\n",
    "\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = image_convolution(f, w)\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An alternative to not produce zero values at the borders is to maintain the original values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_convolution(f, w, debug=False):\n",
    "    N,M = f.shape\n",
    "    n,m = w.shape\n",
    "    \n",
    "    a = int((n-1)/2)\n",
    "    b = int((m-1)/2)\n",
    "\n",
    "    # flipped filter\n",
    "    w_flip = np.flip( np.flip(w, 0) , 1)\n",
    "    # new image to store filtered pixels\n",
    "    # copies the original image 'f' so that border pixels remain the same\n",
    "    g = np.array(f, copy=True)\n",
    "\n",
    "    # for every pixel\n",
    "    for x in range(a,N-a):\n",
    "        for y in range(b,M-b):\n",
    "            # gets subimage\n",
    "            sub_f = f[ x-a : x+a+1 , y-b:y+b+1 ]\n",
    "            if (debug==True):\n",
    "                print(str(x)+\",\"+str(y)+\" - subimage:\\n\"+str(sub_f))\n",
    "            # computes g at (x,y)\n",
    "            g[x,y] = np.sum( np.multiply(sub_f, w_flip)).astype(np.uint8)\n",
    "\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = image_convolution(f, w)\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A widely used strategy is to *extend the original image* to allow processing all pixels, even the border.\n",
    "\n",
    "**Zero-padding**: the original image is 'framed' by filling the extra rows and columns with zero values. After performing convolution, we crop $g$ to its original volume. As an exercise, modify the convolution function to allow this method as an option."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering images\n",
    "\n",
    "Filters can be designed with different purposes. \n",
    "The most commoly used filters are: **smoothing** filters, that produces images with less local variation, reducing noise, but also suppressing small details and texture; and **differential** filters, that work as derivative operator, which may be used to detect local transitions, enhance local variation, increasing details and noise if present in the image. \n",
    "\n",
    "Let us show some examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = imageio.imread(\"images/pattern.png\")\n",
    "img2 = imageio.imread(\"images/gradient_noise.png\")\n",
    "img3 = imageio.imread(\"images/board.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# an average filter, producing a mean in region 3x3 (symmetric) considering all neighbours\n",
    "w_mean = np.matrix([[1, 1, 1], [1, 1, 1], [1, 1, 1]])/9.0\n",
    "print(w_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img2_mean = image_convolution(img2, w_mean)\n",
    "\n",
    "# showing images\n",
    "plt.figure(figsize=(12,12)) \n",
    "plt.subplot(121)\n",
    "plt.imshow(img2, cmap=\"gray\", vmin=0, vmax=255)\n",
    "plt.title(\"original, noisy\")\n",
    "plt.axis('off')\n",
    "plt.subplot(122)\n",
    "plt.imshow(img2_mean, cmap=\"gray\", vmin=0, vmax=255)\n",
    "plt.title(\"filtered image\")\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the filtered image has pixels on the border that were kept from the original image because we cannot process the *a* pixels on the border (given by $a = (m-1)/2$), where *m* is the filter size.\n",
    "\n",
    "When the filter has lateral size $3$, then $a = 1$ so we have a border size 1.\n",
    "\n",
    "If we had a larger filter, say with laterl size $n,m=7$, then $a,b=3$ and 3 border pixels are not going to be processed. As exercise, design a filter $7\\times 7$ or larger to see this effect.\n",
    "\n",
    "Let us design other filters. First, a differential filter, and then a random filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_diff = np.matrix([[ 0, -1,  0], \n",
    "                    [-1,  4, -1], \n",
    "                    [ 0, -1,  0]])\n",
    "print(w_diff)\n",
    "\n",
    "img1_diff = image_convolution(img1, w_diff)\n",
    "\n",
    "plt.figure(figsize=(12,12)) \n",
    "plt.subplot(121)\n",
    "plt.imshow(img1, cmap=\"gray\", vmin=0, vmax=255)\n",
    "plt.title(\"original image\")\n",
    "plt.axis('off')\n",
    "plt.subplot(122)\n",
    "plt.imshow(img1_diff, cmap=\"gray\", vmin=0, vmax=255)\n",
    "plt.title(\"image filtered with differential filter\")\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# another differential filter, but directional (vertical)\n",
    "w_vert = np.matrix([[-1, 0, 1], \n",
    "                    [-1, 0, 1], \n",
    "                    [-1, 0, 1]])\n",
    "print(w_vert)\n",
    "\n",
    "img1_vert = image_convolution(img1, w_vert)\n",
    "\n",
    "plt.figure(figsize=(12,12)) \n",
    "plt.subplot(121)\n",
    "plt.imshow(img1, cmap=\"gray\", vmin=0, vmax=255)\n",
    "plt.title(\"original image\")\n",
    "plt.axis('off')\n",
    "plt.subplot(122)\n",
    "plt.imshow(img1_vert, cmap=\"gray\", vmin=0, vmax=255)\n",
    "plt.title(\"filtered with vertical differential filter\")\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you inspect the filters above, they all are designed to produce some type of effect in terms of diffusing the pixel values (smoothing, e.g. mean filter) or detecting transitions (differential filters, e.g. vertical borders).\n",
    "\n",
    "But what if we have a *random filter*?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_rand = np.random.random([7,7])\n",
    "print(w_rand)\n",
    "img3_wrand = image_convolution(img3, w_rand)\n",
    "\n",
    "plt.figure(figsize=(12,12)) \n",
    "plt.subplot(121)\n",
    "plt.imshow(img3, cmap=\"gray\", vmin=0, vmax=255)\n",
    "plt.title(\"image board\")\n",
    "plt.axis('off')\n",
    "plt.subplot(122)\n",
    "plt.imshow(img3_wrand, cmap=\"gray\", vmin=0, vmax=255)\n",
    "plt.title(\"filtering with a random filter\")\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It does not look good! But is it an effect of the random filter or is there anything else wrong?\n",
    "\n",
    "Our filter has positive values that sum up to much more than 1, the energy of the local regions will increase. This would, at first, increase only the brightness of the image. But, actually, because we are operating in 8 bits, the effect of such successive convolutions is *overflow* \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(w_rand)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can fix that by, for example, normalizing the filter to sum 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_rand = np.random.random([7,7])\n",
    "w_rand = w_rand/np.sum(w_rand)\n",
    "print(w_rand)\n",
    "img3_wrand = image_convolution(img3, w_rand)\n",
    "\n",
    "plt.figure(figsize=(12,12)) \n",
    "plt.subplot(121)\n",
    "plt.imshow(img3, cmap=\"gray\", vmin=0, vmax=255)\n",
    "plt.title(\"image board\")\n",
    "plt.axis('off')\n",
    "plt.subplot(122)\n",
    "plt.imshow(img3_wrand, cmap=\"gray\", vmin=0, vmax=255)\n",
    "plt.title(\"filtering with a normalized random filter\")\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can visualize the image, but note a random filter does not generate an useful image in terms of visualization, not even enhancing any specific characteristics. In fact this is a random smoothing filter, or random weighed mean filter.\n",
    "\n",
    "Another possible random filter would be to create a random differential filter, normalizing it so that it contains negative and positive value, with zero sum. Try that as an exercise!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, we should design a filter carefully, in terms of the local transformation we want to achieve.\n",
    "\n",
    "Inspect the implemented filters again, try to classify them in terms of which characteristics they enhance. Design other filters, varying the sizes and filtering images to see their effects."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
